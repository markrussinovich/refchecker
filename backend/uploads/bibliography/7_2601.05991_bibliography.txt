\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abeysiriwardana and Sumanathilaka(2024)]{abeysiriwardana2024survey}
Miuru Abeysiriwardana and Deshan Sumanathilaka.
\newblock A survey on lexical ambiguity detection and word sense
  disambiguation.
\newblock \emph{arXiv preprint arXiv:2403.16129}, 2024.

\bibitem[Azuma et~al.(2022)Azuma, Miyanishi, Kurita, and
  Kawanabe]{azuma2022scanqa}
Daichi Azuma, Taiki Miyanishi, Shuhei Kurita, and Motoaki Kawanabe.
\newblock Scanqa: 3d question answering for spatial scene understanding.
\newblock In \emph{proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 19129--19139, 2022.

\bibitem[Berry and Kamsties(2004)]{berry2004ambiguity}
Daniel~M Berry and Erik Kamsties.
\newblock Ambiguity in requirements specification.
\newblock In \emph{Perspectives on software requirements}, pages 7--44.
  Springer, 2004.

\bibitem[Chen et~al.(2020)Chen, Tan, Kuntz, Bansal, and Alterovitz]{LMCR_cite}
Haonan Chen, Hao Tan, Alan Kuntz, Mohit Bansal, and Ron Alterovitz.
\newblock Enabling robots to understand incomplete natural language
  instructions using commonsense reasoning.
\newblock In \emph{2020 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 1963--1969. IEEE, 2020.

\bibitem[Dai et~al.(2024)Dai, Peng, Li, and Chai]{ZIPON_cite}
Yinpei Dai, Run Peng, Sikai Li, and Joyce Chai.
\newblock Think, act, and ask: Open-world interactive personalized robot
  navigation.
\newblock In \emph{2024 IEEE international conference on robotics and
  automation (ICRA)}, pages 3296--3303. IEEE, 2024.

\bibitem[Ding et~al.(2025)Ding, Liu, Pan, Long, and Li]{ding2025polysemous}
Jiayu Ding, Xinpeng Liu, Zhiyi Pan, Shiqiang Long, and Ge Li.
\newblock Polysemous language gaussian splatting via matching-based mask
  lifting.
\newblock \emph{arXiv preprint arXiv:2509.22225}, 2025.

\bibitem[Frost et~al.(1990)Frost, Feldman, and Katz]{frost1990phonological}
Ram Frost, Laurie~B Feldman, and Leonard Katz.
\newblock Phonological ambiguity and lexical ambiguity: Effects on visual and
  auditory word recognition.
\newblock \emph{Journal of Experimental Psychology: Learning, Memory, and
  Cognition}, 16\penalty0 (4):\penalty0 569, 1990.

\bibitem[He et~al.()He, Jie, Wang, Zhou, Hu, Li, and Ding]{ReferSplat}
Shuting He, Guangquan Jie, Changshuo Wang, Yun Zhou, Shuming Hu, Guanbin Li,
  and Henghui Ding.
\newblock {ReferSplat}: Referring segmentation in 3d gaussian splatting.
\newblock In \emph{International Conference on Machine Learning}.

\bibitem[Hong et~al.(2023)Hong, Zhen, Chen, Zheng, Du, Chen, and
  Gan]{hong20233d}
Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen,
  and Chuang Gan.
\newblock 3d-llm: Injecting the 3d world into large language models.
\newblock \emph{Advances in Neural Information Processing Systems},
  36:\penalty0 20482--20494, 2023.

\bibitem[Hu et~al.(2022)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, Chen,
  et~al.]{hu2022lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu Wang, Weizhu Chen, et~al.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{ICLR}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Huang et~al.(2024)Huang, Chen, Wang, Huang, Xu, Wang, Liu, Cheng,
  Zhao, Pang, et~al.]{huang2024chat}
Haifeng Huang, Yilun Chen, Zehan Wang, Rongjie Huang, Runsen Xu, Tai Wang,
  Luping Liu, Xize Cheng, Yang Zhao, Jiangmiao Pang, et~al.
\newblock Chat-scene: Bridging 3d scene and large language models with object
  identifiers.
\newblock \emph{Advances in Neural Information Processing Systems},
  37:\penalty0 113991--114017, 2024.

\bibitem[Kamath et~al.(2021)Kamath, Singh, LeCun, Synnaeve, Misra, and
  Carion]{kamath2021mdetr}
Aishwarya Kamath, Mannat Singh, Yann LeCun, Gabriel Synnaeve, Ishan Misra, and
  Nicolas Carion.
\newblock Mdetr-modulated detection for end-to-end multi-modal understanding.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 1780--1790, 2021.

\bibitem[Liu et~al.(2017)Liu, Wang, and Yang]{liu2017referring}
Jingyu Liu, Liang Wang, and Ming-Hsuan Yang.
\newblock Referring expression generation and comprehension via attributes.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 4856--4864, 2017.

\bibitem[Liu et~al.(2024)Liu, Zeng, Ren, Li, Zhang, Yang, Jiang, Li, Yang, Su,
  et~al.]{liu2024grounding}
Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Qing
  Jiang, Chunyuan Li, Jianwei Yang, Hang Su, et~al.
\newblock Grounding dino: Marrying dino with grounded pre-training for open-set
  object detection.
\newblock In \emph{European conference on computer vision}, pages 38--55.
  Springer, 2024.

\bibitem[Magassouba et~al.(2018)Magassouba, Sugiura, and Kawai]{MMC-GAN_cite}
Aly Magassouba, Komei Sugiura, and Hisashi Kawai.
\newblock A multimodal classifier generative adversarial network for carry and
  place tasks from ambiguous language instructions.
\newblock \emph{IEEE Robotics and Automation Letters}, 3\penalty0 (4):\penalty0
  3113--3120, 2018.

\bibitem[Majumdar et~al.(2023)Majumdar, Xia, Batra, Guibas,
  et~al.]{FindThis_cite}
Arjun Majumdar, Fei Xia, Dhruv Batra, Leonidas Guibas, et~al.
\newblock Findthis: Language-driven object disambiguation in indoor
  environments.
\newblock In \emph{7th Annual Conference on Robot Learning}, 2023.

\bibitem[Peth{\"o}(2001)]{petho2001polysemy}
Gergely Peth{\"o}.
\newblock What is polysemy? a survey of current research and results.
\newblock \emph{Pragmatics and the flexibility of word meaning}, pages
  175--224, 2001.

\bibitem[Poesio(1995)]{poesio1995semantic}
Massimo Poesio.
\newblock Semantic ambiguity and perceived ambiguity.
\newblock \emph{arXiv preprint cmp-lg/9505034}, 1995.

\bibitem[Qiao et~al.(2020)Qiao, Deng, and Wu]{qiao2020referring}
Yanyuan Qiao, Chaorui Deng, and Qi Wu.
\newblock Referring expression comprehension: A survey of methods and datasets.
\newblock \emph{IEEE Transactions on Multimedia}, 23:\penalty0 4426--4440,
  2020.

\bibitem[Ren et~al.(2023)Ren, Dixit, Bodrova, Singh, Tu, Brown, Xu, Takayama,
  Xia, Varley, et~al.]{KnowNo_cite}
Allen~Z Ren, Anushri Dixit, Alexandra Bodrova, Sumeet Singh, Stephen Tu, Noah
  Brown, Peng Xu, Leila Takayama, Fei Xia, Jake Varley, et~al.
\newblock Robots that ask for help: Uncertainty alignment for large language
  model planners.
\newblock \emph{arXiv preprint arXiv:2307.01928}, 2023.

\bibitem[Tabanakova et~al.(2021)]{tabanakova2021term}
Vera~Dmitrievna Tabanakova et~al.
\newblock Term “homonymy” as a semantic category.
\newblock \emph{European Proceedings of Social and Behavioural Sciences}, 2021.

\bibitem[Taioli et~al.(2025)Taioli, Zorzi, Franchi, Castellini, Farinelli,
  Cristani, and Wang]{CoIN_cite}
Francesco Taioli, Edoardo Zorzi, Gianni Franchi, Alberto Castellini, Alessandro
  Farinelli, Marco Cristani, and Yiming Wang.
\newblock Collaborative instance object navigation: Leveraging
  uncertainty-awareness to minimize human-agent dialogues.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 18781--18792, 2025.

\bibitem[Weerakoon et~al.(2020)Weerakoon, Subbaraju, Karumpulli, Tran, Xu, Tan,
  Lim, and Misra]{M2Gestic_cite}
Dulanga Weerakoon, Vigneshwaran Subbaraju, Nipuni Karumpulli, Tuan Tran, Qianli
  Xu, U-Xuan Tan, Joo~Hwee Lim, and Archan Misra.
\newblock Gesture enhanced comprehension of ambiguous human-to-robot
  instructions.
\newblock In \emph{Proceedings of the 2020 International Conference on
  Multimodal Interaction}, pages 251--259, 2020.

\bibitem[Yadav et~al.(2021)Yadav, Patel, and Shah]{yadav2021comprehensive}
Apurwa Yadav, Aarshil Patel, and Manan Shah.
\newblock A comprehensive review on resolving ambiguities in natural language
  processing.
\newblock \emph{AI Open}, 2:\penalty0 85--92, 2021.

\bibitem[Yang et~al.(2025)Yang, Li, Yang, Zhang, Hui, Zheng, Yu, Gao, Huang,
  Lv, et~al.]{yang2025qwen3}
An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen
  Yu, Chang Gao, Chengen Huang, Chenxu Lv, et~al.
\newblock Qwen3 technical report.
\newblock \emph{arXiv preprint arXiv:2505.09388}, 2025.

\bibitem[Zhang et~al.(2023)Zhang, Gong, and Chang]{zhang2023multi3drefer}
Yiming Zhang, ZeMing Gong, and Angel~X Chang.
\newblock Multi3drefer: Grounding text description to multiple 3d objects.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 15225--15236, 2023.

\bibitem[Zheng et~al.(2025)Zheng, Huang, and Wang]{zheng2025video}
Duo Zheng, Shijia Huang, and Liwei Wang.
\newblock Video-3d llm: Learning position-aware video representation for 3d
  scene understanding.
\newblock In \emph{Proceedings of the Computer Vision and Pattern Recognition
  Conference}, pages 8995--9006, 2025.

\bibitem[Zhi et~al.(2025)Zhi, Chen, Li, Ma, Sun, Xiang, Lei, Tan, and
  Gan]{zhi2025lscenellm}
Hongyan Zhi, Peihao Chen, Junyan Li, Shuailei Ma, Xinyu Sun, Tianhang Xiang,
  Yinjie Lei, Mingkui Tan, and Chuang Gan.
\newblock Lscenellm: Enhancing large 3d scene understanding using adaptive
  visual preferences.
\newblock In \emph{Proceedings of the Computer Vision and Pattern Recognition
  Conference}, pages 3761--3771, 2025.

\bibitem[Zhu et~al.(2025)Zhu, Wang, Zhang, Pang, and Liu]{zhu2025llava}
Chenming Zhu, Tai Wang, Wenwei Zhang, Jiangmiao Pang, and Xihui Liu.
\newblock Llava-3d: A simple yet effective pathway to empowering lmms with 3d
  capabilities.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4295--4305, 2025.

\bibitem[Zhu et~al.(2023)Zhu, Ma, Chen, Deng, Huang, and Li]{zhu20233d}
Ziyu Zhu, Xiaojian Ma, Yixin Chen, Zhidong Deng, Siyuan Huang, and Qing Li.
\newblock 3d-vista: Pre-trained transformer for 3d vision and text alignment.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2911--2921, 2023.

\end{thebibliography}
