\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmadian et~al.(2024)Ahmadian, Cremer, Gall{\'e}, Fadaee, Kreutzer, Pietquin, {\"U}st{\"u}n, and Hooker]{ahmadian2024back}
Arash Ahmadian, Chris Cremer, Matthias Gall{\'e}, Marzieh Fadaee, Julia Kreutzer, Olivier Pietquin, Ahmet {\"U}st{\"u}n, and Sara Hooker.
\newblock Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms.
\newblock \emph{arXiv preprint arXiv:2402.14740}, 2024.

\bibitem[Azar et~al.(2024)Azar, Rowland, Piot, Guo, Calandriello, Valko, and Munos]{Azar2023IPO}
Mohammad~Gheshlaghi Azar, Mark Rowland, Bilal Piot, Daniel Guo, Daniele Calandriello, Michal Valko, and R{\'e}mi Munos.
\newblock A general theoretical paradigm to understand learning from human preferences.
\newblock \emph{International Conference on Artificial Intelligence and Statistics}, abs/2310.12036, 2024.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Liu, Du, Pang, Liu, Sinha, Varakantham, and Lin]{chen2024bootstrapping}
Changyu Chen, Zichen Liu, Chao Du, Tianyu Pang, Qian Liu, Arunesh Sinha, Pradeep Varakantham, and Min Lin.
\newblock Bootstrapping language models with dpo implicit rewards.
\newblock \emph{arXiv preprint arXiv:2406.09760}, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, He, Yuan, Cui, Su, and Zhu]{chen2024noise}
Huayu Chen, Guande He, Lifan Yuan, Ganqu Cui, Hang Su, and Jun Zhu.
\newblock Noise contrastive alignment of language models with explicit rewards.
\newblock \emph{arXiv preprint arXiv:2402.05369}, 2024{\natexlab{b}}.

\bibitem[Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and Amodei]{christiano2017deep}
Paul~F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei.
\newblock Deep reinforcement learning from human preferences.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Cui et~al.(2024)Cui, Yuan, Ding, Yao, He, Zhu, Ni, Xie, Xie, Lin, Liu, and Sun]{Cui2023ULTRAFEEDBACKBL}
Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Bingxiang He, Wei Zhu, Yuan Ni, Guotong Xie, Ruobing Xie, Yankai Lin, Zhiyuan Liu, and Maosong Sun.
\newblock Ultrafeedback: Boosting language models with scaled ai feedback.
\newblock In \emph{ICML}, 2024.

\bibitem[DeepSeek-AI et~al.(2025)DeepSeek-AI, Guo, Yang, Zhang, Song, Zhang, Xu, Zhu, Ma, Wang, Bi, Zhang, Yu, Wu, Wu, Gou, Shao, Li, Gao, Liu, Xue, Wang, Wu, Feng, Lu, Zhao, Deng, Zhang, Ruan, Dai, Chen, Ji, Li, Lin, Dai, Luo, Hao, Chen, Li, Zhang, Bao, Xu, Wang, Ding, Xin, Gao, Qu, Li, Guo, Li, Wang, Chen, Yuan, Qiu, Li, Cai, Ni, Liang, Chen, Dong, Hu, Gao, Guan, Huang, Yu, Wang, Zhang, Zhao, Wang, Zhang, Xu, Xia, Zhang, Zhang, Tang, Li, Wang, Li, Tian, Huang, Zhang, Wang, Chen, Du, Ge, Zhang, Pan, Wang, Chen, Jin, Chen, Lu, Zhou, Chen, Ye, Wang, Yu, Zhou, Pan, Li, Zhou, Wu, Ye, Yun, Pei, Sun, Wang, Zeng, Zhao, Liu, Liang, Gao, Yu, Zhang, Xiao, An, Liu, Wang, Chen, Nie, Cheng, Liu, Xie, Liu, Yang, Li, Su, Lin, Li, Jin, Shen, Chen, Sun, Wang, Song, Zhou, Wang, Shan, Li, Wang, Wei, Zhang, Xu, Li, Zhao, Sun, Wang, Yu, Zhang, Shi, Xiong, He, Piao, Wang, Tan, Ma, Liu, Guo, Ou, Wang, Gong, Zou, He, Xiong, Luo, You, Liu, Zhou, Zhu, Xu, Huang, Li, Zheng, Zhu, Ma, Tang, Zha, Yan, Ren, Ren, Sha, Fu, Xu, Xie, Zhang,
  Hao, Ma, Yan, Wu, Gu, Zhu, Liu, Li, Xie, Song, Pan, Huang, Xu, Zhang, and Zhang]{deepseekai2025deepseekr1incentivizingreasoningcapability}
DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu~Wu, Z.~F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H.~Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J.~L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong
  Zhang, Ruizhe Pan, Runji Wang, R.~J. Chen, R.~L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S.~S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T.~Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W.~L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X.~Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y.~K. Li, Y.~Q. Wang, Y.~X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi~Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y.~X. Zhu,
  Yanhong Xu, Yanping Huang, Yaohui Li, Yi~Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z.~Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen Zhang.
\newblock Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025.
\newblock URL \url{https://arxiv.org/abs/2501.12948}.

\bibitem[Ethayarajh et~al.(2024)Ethayarajh, Xu, Muennighoff, Jurafsky, and Kiela]{Ethayarajh2024KTOMA}
Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe Kiela.
\newblock Kto: Model alignment as prospect theoretic optimization.
\newblock \emph{ICML}, 2024.

\bibitem[Gao et~al.(2024)Gao, Xu, Ye, Liu, He, Fu, Mei, Wang, and Wu]{Gao2024OnDE}
Jiaxuan Gao, Shusheng Xu, Wenjie Ye, Weiling Liu, Chuyi He, Wei Fu, Zhiyu Mei, Guangju Wang, and Yi~Wu.
\newblock On designing effective rl reward at training time for llm reasoning.
\newblock \emph{ArXiv}, abs/2410.15115, 2024.

\bibitem[Gao et~al.(2022)Gao, Schulman, and Hilton]{Gao2022ScalingLF}
Leo Gao, John Schulman, and Jacob Hilton.
\newblock Scaling laws for reward model overoptimization.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Guo et~al.(2024)Guo, Zhu, Yang, Xie, Dong, Zhang, Chen, Bi, Wu, Li, et~al.]{guo2024deepseek}
Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Yu~Wu, YK~Li, et~al.
\newblock Deepseek-coder: When the large language model meets programming--the rise of code intelligence.
\newblock \emph{arXiv preprint arXiv:2401.14196}, 2024.

\bibitem[Haarnoja et~al.(2017)Haarnoja, Tang, Abbeel, and Levine]{DBLP:conf/icml/HaarnojaTAL17}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock In Doina Precup and Yee~Whye Teh (eds.), \emph{Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017}, volume~70 of \emph{Proceedings of Machine Learning Research}, pp.\  1352--1361. {PMLR}, 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/haarnoja17a.html}.

\bibitem[He et~al.(2024)He, Luo, Bai, Hu, Thai, Shen, Hu, Han, Huang, Zhang, Liu, Qi, Liu, and Sun]{he-etal-2024-olympiadbench}
Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen Thai, Junhao Shen, Jinyi Hu, Xu~Han, Yujie Huang, Yuxiang Zhang, Jie Liu, Lei Qi, Zhiyuan Liu, and Maosong Sun.
\newblock {O}lympiad{B}ench: A challenging benchmark for promoting {AGI} with olympiad-level bilingual multimodal scientific problems.
\newblock In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  3828--3850, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.acl-long.211}.
\newblock URL \url{https://aclanthology.org/2024.acl-long.211/}.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Basart, Kadavath, Mazeika, Arora, Guo, Burns, Puranik, He, Song, et~al.]{apps}
Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, et~al.
\newblock Measuring coding challenge competence with apps.
\newblock \emph{arXiv preprint arXiv:2105.09938}, 2021{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Burns, Kadavath, Arora, Basart, Tang, Song, and Steinhardt]{hendrycks2021measuring}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock \emph{arXiv preprint arXiv:2103.03874}, 2021{\natexlab{b}}.

\bibitem[Jaech et~al.(2024)Jaech, Kalai, Lerer, Richardson, El-Kishky, Low, Helyar, Madry, Beutel, Carney, et~al.]{jaech2024openai}
Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et~al.
\newblock Openai o1 system card.
\newblock \emph{arXiv preprint arXiv:2412.16720}, 2024.

\bibitem[Jain et~al.(2024)Jain, Han, Gu, Li, Yan, Zhang, Wang, Solar-Lezama, Sen, and Stoica]{jain2024livecodebench}
Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica.
\newblock Livecodebench: Holistic and contamination free evaluation of large language models for code.
\newblock \emph{arXiv preprint arXiv:2403.07974}, 2024.

\bibitem[Kazemnejad et~al.(2024)Kazemnejad, Aghajohari, Portelance, Sordoni, Reddy, Courville, and Roux]{kazemnejad2024vineppo}
Amirhossein Kazemnejad, Milad Aghajohari, Eva Portelance, Alessandro Sordoni, Siva Reddy, Aaron Courville, and Nicolas~Le Roux.
\newblock Vineppo: Unlocking rl potential for llm reasoning through refined credit assignment.
\newblock \emph{arXiv preprint arXiv:2410.01679}, 2024.

\bibitem[Kool et~al.(2019)Kool, van Hoof, and Welling]{Kool2019Buy4R}
Wouter Kool, Herke van Hoof, and Max Welling.
\newblock Buy 4 reinforce samples, get a baseline for free!
\newblock In \emph{DeepRLStructPred@ICLR}, 2019.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:198489118}.

\bibitem[Lambert et~al.(2024)Lambert, Morrison, Pyatkin, Huang, Ivison, Brahman, Miranda, Liu, Dziri, Lyu, Gu, Malik, Graf, Hwang, Yang, Bras, Tafjord, Wilhelm, Soldaini, Smith, Wang, Dasigi, and Hajishirzi]{Lambert2024TLU3P}
Nathan Lambert, Jacob~Daniel Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James~Validad Miranda, Alisa Liu, Nouha Dziri, Xinxi Lyu, Yuling Gu, Saumya Malik, Victoria Graf, Jena~D. Hwang, Jiangjiang Yang, Ronan~Le Bras, Oyvind Tafjord, Chris Wilhelm, Luca Soldaini, Noah~A. Smith, Yizhong Wang, Pradeep Dasigi, and Hanna Hajishirzi.
\newblock T{\"u}lu 3: Pushing frontiers in open language model post-training.
\newblock \emph{ArXiv}, abs/2411.15124, 2024.

\bibitem[Leike et~al.(2018)Leike, Krueger, Everitt, Martic, Maini, and Legg]{leike2018scalable}
Jan Leike, David Krueger, Tom Everitt, Miljan Martic, Vishal Maini, and Shane Legg.
\newblock Scalable agent alignment via reward modeling: a research direction.
\newblock \emph{arXiv preprint arXiv:1811.07871}, 2018.

\bibitem[Lewkowycz et~al.(2022)Lewkowycz, Andreassen, Dohan, Dyer, Michalewski, Ramasesh, Slone, Anil, Schlag, Gutman-Solo, et~al.]{lewkowycz2022solving}
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et~al.
\newblock Solving quantitative reasoning problems with language models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 3843--3857, 2022.

\bibitem[Li et~al.(2024)Li, Beeching, Tunstall, Lipkin, Soletskyi, Huang, Rasul, Yu, Jiang, Shen, et~al.]{li2024numinamath}
Jia Li, Edward Beeching, Lewis Tunstall, Ben Lipkin, Roman Soletskyi, Shengyi Huang, Kashif Rasul, Longhui Yu, Albert~Q Jiang, Ziju Shen, et~al.
\newblock Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions.
\newblock \emph{Hugging Face repository}, 13:\penalty0 9, 2024.

\bibitem[Li et~al.(2023)Li, Fu, Zhang, Huang, Sun, Lyu, Liu, Jin, and Li]{li2023taco}
Rongao Li, Jie Fu, Bo-Wen Zhang, Tao Huang, Zhihong Sun, Chen Lyu, Guang Liu, Zhi Jin, and Ge~Li.
\newblock Taco: Topics in algorithmic code generation dataset.
\newblock \emph{arXiv preprint arXiv:2312.14852}, 2023.

\bibitem[Li et~al.(2022)Li, Choi, Chung, Kushman, Schrittwieser, Leblond, Eccles, Keeling, Gimeno, Dal~Lago, Hubert, Choy, de~Masson~d'Autume, Babuschkin, Chen, Huang, Welbl, Gowal, Cherepanov, Molloy, Mankowitz, Sutherland~Robson, Kohli, de~Freitas, Kavukcuoglu, and Vinyals]{li2022competition}
Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R{\'e}mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal~Lago, Thomas Hubert, Peter Choy, Cyprien de~Masson~d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel Mankowitz, Esme Sutherland~Robson, Pushmeet Kohli, Nando de~Freitas, Koray Kavukcuoglu, and Oriol Vinyals.
\newblock Competition-level code generation with alphacode.
\newblock \emph{arXiv preprint arXiv:2203.07814}, 2022.

\bibitem[Lightman et~al.(2023)Lightman, Kosaraju, Burda, Edwards, Baker, Lee, Leike, Schulman, Sutskever, and Cobbe]{Lightman2023LetsVS}
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.
\newblock Let's verify step by step.
\newblock \emph{ArXiv}, abs/2305.20050, 2023.

\bibitem[Lin et~al.(2024)Lin, Gou, Gong, Liu, Shen, Xu, Lin, Yang, Jiao, Duan, and Chen]{lin2024rho1}
Zhenghao Lin, Zhibin Gou, Yeyun Gong, Xiao Liu, Yelong Shen, Ruochen Xu, Chen Lin, Yujiu Yang, Jian Jiao, Nan Duan, and Weizhu Chen.
\newblock Rho-1: Not all tokens are what you need, 2024.

\bibitem[Liu et~al.(2024)Liu, Chen, Shoeybi, Catanzaro, and Ping]{liu2024acemath}
Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping.
\newblock Acemath: Advancing frontier math reasoning with post-training and reward modeling.
\newblock \emph{arXiv preprint arXiv:2412.15084}, 2024.

\bibitem[Luo et~al.(2025)Luo, Tan, Wong, Shi, Tang, Roongta, Cai, Luo, Li, Popa, and Stoica]{deepscaler2025}
Michael Luo, Sijun Tan, Justin Wong, Xiaoxiang Shi, William~Y. Tang, Manan Roongta, Colin Cai, Jeffrey Luo, Li~Erran Li, Raluca~Ada Popa, and Ion Stoica.
\newblock Deepscaler: Surpassing o1-preview with a 1.5b model by scaling rl.
\newblock \url{https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2}, 2025.
\newblock Notion Blog.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{DBLP:conf/icml/NgHR99}
Andrew~Y. Ng, Daishi Harada, and Stuart Russell.
\newblock Policy invariance under reward transformations: Theory and application to reward shaping.
\newblock In Ivan Bratko and Saso Dzeroski (eds.), \emph{Proceedings of the Sixteenth International Conference on Machine Learning {(ICML} 1999), Bled, Slovenia, June 27 - 30, 1999}, pp.\  278--287. Morgan Kaufmann, 1999.

\bibitem[OpenAI(2024)]{Openai2024OpenAIOS}
OpenAI.
\newblock Openai o1 system card.
\newblock \emph{ArXiv}, abs/2412.16720, 2024.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 27730--27744, 2022.

\bibitem[Rafailov et~al.(2023)Rafailov, Sharma, Mitchell, Manning, Ermon, and Finn]{rafailov2024direct}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher~D Manning, Stefano Ermon, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem[Rafailov et~al.(2024)Rafailov, Hejna, Park, and Finn]{rafailov2024r}
Rafael Rafailov, Joey Hejna, Ryan Park, and Chelsea Finn.
\newblock From $ r $ to $ q^{*}$: Your language model is secretly a q-function.
\newblock \emph{arXiv preprint arXiv:2404.12358}, 2024.

\bibitem[Rosset et~al.(2024)Rosset, Cheng, Mitra, Santacroce, Awadallah, and Xie]{Rosset2024DirectNO}
Corby Rosset, Ching-An Cheng, Arindam Mitra, Michael Santacroce, Ahmed Awadallah, and Tengyang Xie.
\newblock Direct nash optimization: Teaching language models to self-improve with general preferences.
\newblock \emph{ArXiv}, abs/2404.03715, 2024.

\bibitem[Schulman et~al.(2016)Schulman, Moritz, Levine, Jordan, and Abbeel]{SchulmanMLJA15}
John Schulman, Philipp Moritz, Sergey Levine, Michael~I. Jordan, and Pieter Abbeel.
\newblock High-dimensional continuous control using generalized advantage estimation.
\newblock In \emph{4th International Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings}, 2016.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Setlur et~al.(2024)Setlur, Nagpal, Fisch, Geng, Eisenstein, Agarwal, Agarwal, Berant, and Kumar]{setlur2024rewarding}
Amrith Setlur, Chirag Nagpal, Adam Fisch, Xinyang Geng, Jacob Eisenstein, Rishabh Agarwal, Alekh Agarwal, Jonathan Berant, and Aviral Kumar.
\newblock Rewarding progress: Scaling automated process verifiers for llm reasoning.
\newblock \emph{arXiv preprint arXiv:2410.08146}, 2024.

\bibitem[Shao et~al.(2024)Shao, Wang, Zhu, Xu, Song, Bi, Zhang, Zhang, Li, Wu, and Guo]{deepseek-math}
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y.~K. Li, Y.~Wu, and Daya Guo.
\newblock Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.03300}.

\bibitem[Sheng et~al.(2024)Sheng, Zhang, Ye, Wu, Zhang, Zhang, Peng, Lin, and Wu]{sheng2024hybridflow}
Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru~Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu.
\newblock Hybridflow: A flexible and efficient rlhf framework.
\newblock \emph{arXiv preprint arXiv: 2409.19256}, 2024.

\bibitem[SkunkworksAI(2024)]{reasoning001}
SkunkworksAI.
\newblock reasoning-0.01, 2024.

\bibitem[Sutton(2019)]{sutton2019bitter}
Richard Sutton.
\newblock The bitter lesson.
\newblock \emph{Incomplete Ideas (blog)}, 13\penalty0 (1):\penalty0 38, 2019.

\bibitem[Sutton(1988)]{sutton1988learning}
Richard~S Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine learning}, 3:\penalty0 9--44, 1988.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Team et~al.(2025)Team, Du, Gao, Xing, Jiang, Chen, Li, Xiao, Du, Liao, et~al.]{team2025kimi}
Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et~al.
\newblock Kimi k1. 5: Scaling reinforcement learning with llms.
\newblock \emph{arXiv preprint arXiv:2501.12599}, 2025.

\bibitem[Team(2024)]{qwq-32b-preview}
Qwen Team.
\newblock Qwq: Reflect deeply on the boundaries of the unknown, November 2024.
\newblock URL \url{https://qwenlm.github.io/blog/qwq-32b-preview/}.

\bibitem[Toshniwal et~al.(2024)Toshniwal, Du, Moshkov, Kisacanin, Ayrapetyan, and Gitman]{toshniwal2024openmath2}
Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, and Igor Gitman.
\newblock Openmathinstruct-2: Accelerating ai for math with massive open-source instruction data.
\newblock \emph{arXiv preprint arXiv:2410.01560}, 2024.

\bibitem[Uesato et~al.(2022)Uesato, Kushman, Kumar, Song, Siegel, Wang, Creswell, Irving, and Higgins]{uesato2022solving}
Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa Wang, Antonia Creswell, Geoffrey Irving, and Irina Higgins.
\newblock Solving math word problems with process-and outcome-based feedback.
\newblock \emph{arXiv preprint arXiv:2211.14275}, 2022.

\bibitem[Wang et~al.(2023)Wang, Li, Shao, Xu, Dai, Li, Chen, Y.Wu, and Sui]{Wang2023MathShepherdVA}
Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Y.Wu, and Zhifang Sui.
\newblock Math-shepherd: Verify and reinforce llms step-by-step without human annotations.
\newblock \emph{ArXiv}, abs/2312.08935, 2023.

\bibitem[Wei et~al.(2024)Wei, Wang, Liu, Ding, and Zhang]{wei2024magicoder}
Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang.
\newblock Magicoder: Empowering code generation with oss-instruct.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.

\bibitem[Williams(1992)]{williams1992simple}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist reinforcement learning.
\newblock \emph{Machine learning}, 8:\penalty0 229--256, 1992.

\bibitem[Yang et~al.(2024{\natexlab{a}})Yang, Yang, Zhang, Hui, Zheng, Yu, Li, Liu, Huang, Wei, Lin, Yang, Tu, Zhang, Yang, Yang, Zhou, Lin, Dang, Lu, Bao, Yang, Yu, Li, Xue, Zhang, Zhu, Men, Lin, Li, Xia, Ren, Ren, Fan, Su, Zhang, Wan, Liu, Cui, Zhang, and Qiu]{qwen2.5}
An~Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo~Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le~Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu~Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu.
\newblock Qwen2.5 technical report.
\newblock \emph{arXiv preprint arXiv:2412.15115}, 2024{\natexlab{a}}.

\bibitem[Yang et~al.(2024{\natexlab{b}})Yang, Zhang, Hui, Gao, Yu, Li, Liu, Tu, Zhou, Lin, Lu, Xue, Lin, Liu, Ren, and Zhang]{yang2024qwen25mathtechnicalreportmathematical}
An~Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, Keming Lu, Mingfeng Xue, Runji Lin, Tianyu Liu, Xingzhang Ren, and Zhenru Zhang.
\newblock Qwen2.5-math technical report: Toward mathematical expert model via self-improvement, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2409.12122}.

\bibitem[Yuan et~al.(2024{\natexlab{a}})Yuan, Cui, Wang, Ding, Wang, Deng, Shan, Chen, Xie, Lin, Liu, Zhou, Peng, Liu, and Sun]{Yuan2024AdvancingLR}
Lifan Yuan, Ganqu Cui, Hanbin Wang, Ning Ding, Xingyao Wang, Jia Deng, Boji Shan, Huimin Chen, Ruobing Xie, Yankai Lin, Zhenghao Liu, Bowen Zhou, Hao Peng, Zhiyuan Liu, and Maosong Sun.
\newblock Advancing llm reasoning generalists with preference trees.
\newblock \emph{ArXiv}, 2024{\natexlab{a}}.

\bibitem[Yuan et~al.(2024{\natexlab{b}})Yuan, Li, Chen, Cui, Ding, Zhang, Zhou, Liu, and Peng]{yuan2024freeprocessrewardsprocess}
Lifan Yuan, Wendi Li, Huayu Chen, Ganqu Cui, Ning Ding, Kaiyan Zhang, Bowen Zhou, Zhiyuan Liu, and Hao Peng.
\newblock Free process rewards without process labels, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2412.01981}.

\bibitem[Yue et~al.(2023)Yue, Qu, Zhang, Fu, Huang, Sun, Su, and Chen]{yue2023mammoth}
Xiang Yue, Xingwei Qu, Ge~Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu~Su, and Wenhu Chen.
\newblock Mammoth: Building math generalist models through hybrid instruction tuning.
\newblock \emph{arXiv preprint arXiv:2309.05653}, 2023.

\bibitem[Yue et~al.(2024)Yue, Zheng, Zhang, and Chen]{Yue2024MAmmoTH2SI}
Xiang Yue, Tuney Zheng, Ge~Zhang, and Wenhu Chen.
\newblock Mammoth2: Scaling instructions from the web.
\newblock \emph{ArXiv}, abs/2405.03548, 2024.

\bibitem[Zhang et~al.(2024)Zhang, Zeng, Hua, Ding, Chen, Ma, Li, Cui, Qi, Zhu, Lv, Jinfang, Liu, and Zhou]{zhang2024ultramedical}
Kaiyan Zhang, Sihang Zeng, Ermo Hua, Ning Ding, Zhang-Ren Chen, Zhiyuan Ma, Haoxin Li, Ganqu Cui, Biqing Qi, Xuekai Zhu, Xingtai Lv, Hu~Jinfang, Zhiyuan Liu, and Bowen Zhou.
\newblock Ultramedical: Building specialized generalists in biomedicine, 2024.

\bibitem[Zheng et~al.(2024)Zheng, Zhang, Shen, Liu, Lin, Fu, Chen, and Yue]{zheng2024opencodeinterpreter}
Tianyu Zheng, Ge~Zhang, Tianhao Shen, Xueling Liu, Bill~Yuchen Lin, Jie Fu, Wenhu Chen, and Xiang Yue.
\newblock Opencodeinterpreter: Integrating code generation with execution and refinement.
\newblock \emph{arXiv preprint arXiv:2402.14658}, 2024.

\bibitem[Zhou et~al.(2024)Zhou, Liu, Liu, Dong, Yang, and Qiao]{zhou2024weak}
Zhanhui Zhou, Zhixuan Liu, Jie Liu, Zhichen Dong, Chao Yang, and Yu~Qiao.
\newblock Weak-to-strong search: Align large language models via searching over small language models.
\newblock \emph{arXiv preprint arXiv:2405.19262}, 2024.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and Dey]{DBLP:conf/aaai/ZiebartMBD08}
Brian~D. Ziebart, Andrew~L. Maas, J.~Andrew Bagnell, and Anind~K. Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In Dieter Fox and Carla~P. Gomes (eds.), \emph{Proceedings of the Twenty-Third {AAAI} Conference on Artificial Intelligence, {AAAI} 2008, Chicago, Illinois, USA, July 13-17, 2008}, pp.\  1433--1438. {AAAI} Press, 2008.
\newblock URL \url{http://www.aaai.org/Library/AAAI/2008/aaai08-227.php}.

\end{thebibliography}
